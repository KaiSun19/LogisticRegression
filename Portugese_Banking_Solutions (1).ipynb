{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Portugese Banking Solutions",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPxVKdAaSQ65"
      },
      "source": [
        "#**Portugese Bank Marketing Solution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WpAwz_KRwyg"
      },
      "source": [
        "Step 1 : Import packages "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hk3iNFAqxUGC"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk4Bn7cN4Tc1"
      },
      "source": [
        "Step 2 : Load dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9759chKk4nB2"
      },
      "source": [
        "\n",
        "```\n",
        "url = \"https://raw.githubusercontent.com/KaiSun19/LogisticRegression/data/bank_cleaned.csv\"\n",
        "dataset = pd.read_csv(url)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1edG0Jo5htc"
      },
      "source": [
        "Step 3 : Create dummies for qualitative data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyHYutka5bo1"
      },
      "source": [
        "\n",
        "```\n",
        "job = pd.get_dummies(dataset[\"job\"], drop_first=True)\n",
        "marital = pd.get_dummies(dataset[\"marital\"], drop_first=True)\n",
        "education = pd.get_dummies(dataset[\"education\"], drop_first=True)\n",
        "default = pd.get_dummies(dataset[\"default\"], drop_first=True)\n",
        "housing = pd.get_dummies(dataset[\"housing\"], drop_first=True)\n",
        "loan = pd.get_dummies(dataset[\"loan\"], drop_first=True)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7wEdo1T5uhm"
      },
      "source": [
        "Step 4: Remove irrelevant data to customer information and concatenate quantitative data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6oWyvnv541r"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "dataset.drop([\"job\", \"marital\", \"education\", \"default\", \"housing\", \"loan\", \"campaign\",\"pdays\",\"previous\",\"poutcome\",\"response\", \"duration\",\"day\",\"month\", 'Unnamed: 0'] ,axis=1, inplace=True)\n",
        "datasets = [job,marital,education,default,housing,loan,dataset]\n",
        "data = pd.concat(datasets,axis=1)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLWi1VnV2IXF"
      },
      "source": [
        "Step 5: Analyze correlation matrix \n",
        "\n",
        "The full correlation matrix can be found at :\n",
        "\n",
        "https://github.com/KaiSun19/LogisticRegression/blob/figures/banking_correlation_matrix.png\n",
        "\n",
        "We can see that there is only a moderate correlation between some variables e.g. \"tertiary\" and \"secondary\" or \"management\" and \"tertiary\" which is partially due to their role as \"dummy\" variables so there is no obvious problem of multi-colinearity within the data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6BqDS7d5-iw"
      },
      "source": [
        "Step 6 : Identify features and target variables "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jroS0VRx6GyX"
      },
      "source": [
        "\n",
        "```\n",
        "features = [\"blue-collar\", \"entrepreneur\", \"housemaid\", \"management\", \"other\", \"retired\", \"self-employed\", \"services\", \"student\",\n",
        "            \"technician\", \"unemployed\", \"married\", \"single\", \"secondary\", \"tertiary\", \"yes\", \"yes\", \"age\", \"balance\"]\n",
        "target = \"response_binary\"\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5W37txr6L00"
      },
      "source": [
        "Step 7 : Split data into training and testing sets "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X70-Aa4w6Scq"
      },
      "source": [
        "\n",
        "```\n",
        "X = data[features]\n",
        "y= data[target]\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y97Rw2sl6X6B"
      },
      "source": [
        "Step 8: Fit model and and test on test data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GciZGCZL6iUk"
      },
      "source": [
        "\n",
        "```\n",
        "model = LogisticRegression(solver='liblinear', C=0.05, multi_class='ovr',\n",
        "                           random_state=0)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2azR1qot6nj4"
      },
      "source": [
        "Step 9 : Evaluate model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWmXATjM6tjb"
      },
      "source": [
        "\n",
        "```\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "class_names=[0,1] \n",
        "plt.xticks(class_names)\n",
        "plt.yticks(class_names)\n",
        "sns.heatmap(pd.DataFrame(cm), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
        "plt.title('Confusion matrix', y=1.1)\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGoEeDxh7u3i"
      },
      "source": [
        "![Confusion Matrix](https://raw.githubusercontent.com/KaiSun19/LogisticRegression/figures/banking_cm.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8i7VRaI71DC"
      },
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29gtuwbg8Xja"
      },
      "source": [
        "\n",
        "```\n",
        "Accuracy : 0.8874742924297326\n",
        "Precision : 0.0\n",
        "Recall : 0.0\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDebbjbRAx3e"
      },
      "source": [
        "The Precision and Recall score of 0 shows that there is insufficient data of positive outcomes i.e. customers who would subscribe to the term deposit. Therefore, from the raw datsaset there needs to be a rebalancing of target variables before concluding the true accuracy of the algorithm. The accuracy score of 0.88 shows that the algorithm is however accurate in predicting negative outcomes "
      ]
    }
  ]
}