{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Portugese Banking Problem ",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nA9xGYsTKJv"
      },
      "source": [
        "#**Portuguese Banking Problem** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6eSJK_RU9dy"
      },
      "source": [
        "##**Introduction**##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mtvZAboTQVo"
      },
      "source": [
        "The following dataset is from the UCI Machine Learning Repository and is a collection of information about direct marketing calls to customers in attempt to get them to subscribe to a termly deposit "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98YonbTkTpR6"
      },
      "source": [
        "Url for the dataset \n",
        "```\n",
        " https://raw.githubusercontent.com/KaiSun19/LogisticRegression/data/bank_cleaned.csv\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHQhzMGt6Vzo"
      },
      "source": [
        "\n",
        "A sample of the data can be seen below and can also be retrieved using ```data.head()```\n",
        "\n",
        "\n",
        "![Banking Data](https://raw.githubusercontent.com/KaiSun19/LogisticRegression/figures/banking_data_sample.png) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzjRfuXnUPKP"
      },
      "source": [
        "There is a set of customer information and information about the call. As well, there is a response column that has been transformed to binary and called \"response_binary\"\n",
        "\n",
        "The task is to create a Logistic Regression algorithm to accurately identify whether a customer will subscribe based on their personal details. \n",
        "\n",
        "\n",
        "Sections to be completed are as follows :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khnFzlqqUmRw"
      },
      "source": [
        "##**Preparation of Data**##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onF3r4FaWkz9"
      },
      "source": [
        "Transforming qualitative data into numerical data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wATW2_43VEcX"
      },
      "source": [
        "The columns \"job\", \"marital\", \"education\" are qualitative in nature. These pieces of data need to be transformed into binary or dummy variables, representing the categorical data. This is because the algorithms can only take in numerical values . This can be done using \n",
        "\n",
        "```\n",
        "pd.get_dummies(data, drop_first = True) \n",
        "```\n",
        "with parameter \"data\" being the relevant dataset columns. \"drop_first = True\" is used to create k-1 dummy variables out of the total number of categorical levels. E.g. instead of having \"Yes\" and \"No\" variables, only \"Yes\" is needed to fully represent the information, so \"No\" is made redundant and removed  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek9ZCOl7ns9O"
      },
      "source": [
        "Not all of the dataset has data relevant to customer information e.g. information about the call so these will have to be removed using \n",
        "\n",
        "```\n",
        "dataframe.drop(columns) \n",
        "```\n",
        "After, the relevant dummy variables have to be concatenated onto the existing dataframe. This is done using \n",
        "\n",
        "\n",
        "```\n",
        "pd.concat(dataframes, axis = 1 ) \n",
        "```\n",
        "where \"dataframes\" is a list of the dataframes to be concatenated, and axis = 1 is used to concatenate the dataframes along the horizontal axis. The updated dataframe can be saved as a new variable \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FipCTRXr0dQu"
      },
      "source": [
        "\n",
        "Create a correlation matrix to see if there is a problem of multi-colinearity within the dataset \n",
        "\n",
        "As the nature of the data contains categorical values, it would be best  to use ```df.corr(method=\"spearman\")``` in order to compute a correlation matrix. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFQo-ON5pVQF"
      },
      "source": [
        "##**Training and testing the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnPFQAU9pjZZ"
      },
      "source": [
        "Identify the feature variables and assign values to \"X\". Identify the target variable and assign values to \"y\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWOnUjICq1nY"
      },
      "source": [
        "Split data into a training and testing set using \n",
        "\n",
        "```\n",
        "train_test_split(features, target, test_size, random_state ) \n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ089BQqrUg6"
      },
      "source": [
        "\n",
        "Create an instance of the algorithm using \n",
        "\n",
        "```\n",
        "LogisticRegression(solver, C, multi_class, random_state = 0 )\n",
        "```\n",
        "and assign to \"model\" \n",
        "\n",
        " Fit the model to the training set using \n",
        "\n",
        "```\n",
        ".fit() \n",
        "```\n",
        "\n",
        "then predict outcomes using the training set , assign to \"y_pred\" "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2PYgDQwsaZq"
      },
      "source": [
        "**Evaluating the model**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC6QCTT8sgl1"
      },
      "source": [
        "Step 1 : Create a confusion matrix \n",
        "\n",
        "```\n",
        " confusion_matrix() \n",
        "```\n",
        "\n",
        "Step 2 : Plot the confusion matrix onto a heatmap using \n",
        "\n",
        "```\n",
        "sns.heatmap(dataframe,  annot=, cmap= ,fmt=) \n",
        "```\n",
        "\n",
        "Step 3 : Get scores using \n",
        "\n",
        "```\n",
        "accuracy_score()\n",
        "precision_score()\n",
        "recall_score()\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDG3xiH8JSIA"
      },
      "source": [
        "Analyze the confusion matrix and the scores to see how effective the algorithm is at predicting whether a customer would subscribe to a termly deposit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2tltwSHuy07"
      },
      "source": [
        "##**References** \n",
        "bank_cleaned.csv : https://www.kaggle.com/yufengsui/portuguese-bank-marketing-data-set\n"
      ]
    }
  ]
}